{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b95f815c-c356-4826-9927-36bffe69188f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "MODELADO MACHINE LEARNING - PREDICCI√ìN DE ANEMIA INFANTIL\n",
      "ENDES 2015-2024 | ESTRATIFICACI√ìN CRUZADA A√ëO √ó ANEMIA\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "1. CARGANDO DATOS\n",
      "================================================================================\n",
      "\n",
      "Cargando datasets...\n",
      "\n",
      "‚úì TRAIN: 92,030 registros √ó 43 columnas\n",
      "   A√±os: [2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2024]\n",
      "   Prevalencia anemia: 46.33%\n",
      "\n",
      "‚úì TEST:  26,291 registros √ó 43 columnas\n",
      "   A√±os: [2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2024]\n",
      "   Prevalencia anemia: 46.33%\n",
      "\n",
      "‚úì DEV:   13,147 registros √ó 43 columnas\n",
      "   A√±os: [2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2024]\n",
      "   Prevalencia anemia: 46.32%\n",
      "\n",
      "================================================================================\n",
      "2. AN√ÅLISIS EXPLORATORIO\n",
      "================================================================================\n",
      "\n",
      "üìä Distribuci√≥n de ANEMIA por partici√≥n:\n",
      "\n",
      "Partici√≥n    Sin anemia   Con anemia      Total   % Anemia\n",
      "------------------------------------------------------------\n",
      "TRAIN            49,391       42,639     92,030     46.33%\n",
      "TEST             14,111       12,180     26,291     46.33%\n",
      "DEV               7,057        6,090     13,147     46.32%\n",
      "\n",
      "üìã Columnas disponibles: 43\n",
      "   Primeras 10: ['HHID', 'HC0', 'HC51', 'HC1', 'HC27', 'HC53', 'HC55', 'HC57', 'HC70', 'CASEID']\n",
      "\n",
      "================================================================================\n",
      "3. SELECCI√ìN Y PREPARACI√ìN DE FEATURES\n",
      "================================================================================\n",
      "\n",
      "‚úì Features num√©ricas disponibles: 7\n",
      "   ['HC1', 'HC70', 'HV040', 'HW3', 'BORD', 'V012', 'V133']\n",
      "\n",
      "‚úì Features categ√≥ricas disponibles: 6\n",
      "   ['HC27', 'HV024', 'HV025', 'HV237', 'V106', 'V190']\n",
      "\n",
      "‚úì Total features: 13\n",
      "\n",
      "================================================================================\n",
      "4. PREPROCESAMIENTO\n",
      "================================================================================\n",
      "\n",
      "Preprocesando TRAIN...\n",
      "Preprocesando TEST...\n",
      "Preprocesando DEV...\n",
      "\n",
      "‚úì Usando pesos muestrales (variable PESO)\n",
      "   Rango TRAIN: 0.009549 - 4.814230\n",
      "\n",
      "‚úì Preparaci√≥n completada:\n",
      "   X_train: (92030, 13)\n",
      "   X_test:  (26291, 13)\n",
      "   X_dev:   (13147, 13)\n",
      "\n",
      "üîç Verificando missings en X_train:\n",
      "   ‚úì Sin missings\n",
      "\n",
      "================================================================================\n",
      "5. DEFINICI√ìN DE MODELOS\n",
      "================================================================================\n",
      "\n",
      "‚úì Modelos definidos:\n",
      "   ‚Ä¢ Random Forest\n",
      "   ‚Ä¢ XGBoost\n",
      "   ‚Ä¢ LightGBM\n",
      "\n",
      "================================================================================\n",
      "6. ENTRENAMIENTO Y EVALUACI√ìN\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Entrenando: Random Forest\n",
      "================================================================================\n",
      "\n",
      "‚è≥ Entrenando en TRAIN...\n",
      "üìä Evaluando en TRAIN...\n",
      "üìä Evaluando en TEST...\n",
      "üìä Evaluando en DEV...\n",
      "\n",
      "‚úì Random Forest - Resumen:\n",
      "   TRAIN ‚Üí AUC: 0.8649, F1: 0.7472\n",
      "   TEST  ‚Üí AUC: 0.7395, F1: 0.6367\n",
      "   DEV   ‚Üí AUC: 0.7336, F1: 0.6296\n",
      "\n",
      "================================================================================\n",
      "Entrenando: XGBoost\n",
      "================================================================================\n",
      "\n",
      "‚è≥ Entrenando en TRAIN...\n",
      "üìä Evaluando en TRAIN...\n",
      "üìä Evaluando en TEST...\n",
      "üìä Evaluando en DEV...\n",
      "\n",
      "‚úì XGBoost - Resumen:\n",
      "   TRAIN ‚Üí AUC: 0.7768, F1: 0.6716\n",
      "   TEST  ‚Üí AUC: 0.7358, F1: 0.6365\n",
      "   DEV   ‚Üí AUC: 0.7285, F1: 0.6285\n",
      "\n",
      "================================================================================\n",
      "Entrenando: LightGBM\n",
      "================================================================================\n",
      "\n",
      "‚è≥ Entrenando en TRAIN...\n",
      "üìä Evaluando en TRAIN...\n",
      "üìä Evaluando en TEST...\n",
      "üìä Evaluando en DEV...\n",
      "\n",
      "‚úì LightGBM - Resumen:\n",
      "   TRAIN ‚Üí AUC: 0.7612, F1: 0.6593\n",
      "   TEST  ‚Üí AUC: 0.7347, F1: 0.6380\n",
      "   DEV   ‚Üí AUC: 0.7276, F1: 0.6302\n",
      "\n",
      "================================================================================\n",
      "7. COMPARACI√ìN DE MODELOS\n",
      "================================================================================\n",
      "\n",
      "üìä Tabla comparativa de modelos:\n",
      "                  AUC                 Accuracy                      F1  \\\n",
      "Conjunto          DEV    TEST   TRAIN      DEV    TEST   TRAIN     DEV   \n",
      "Modelo                                                                   \n",
      "LightGBM       0.7276  0.7347  0.7612   0.6704  0.6766  0.6942  0.6302   \n",
      "Random Forest  0.7336  0.7395  0.8649   0.6726  0.6780  0.7766  0.6296   \n",
      "XGBoost        0.7285  0.7358  0.7768   0.6707  0.6766  0.7066  0.6285   \n",
      "\n",
      "                              Precision                  Recall          \\\n",
      "Conjunto         TEST   TRAIN       DEV    TEST   TRAIN     DEV    TEST   \n",
      "Modelo                                                                    \n",
      "LightGBM       0.6380  0.6593    0.6197  0.6260  0.6432  0.6411  0.6503   \n",
      "Random Forest  0.6367  0.7472    0.6240  0.6296  0.7402  0.6352  0.6439   \n",
      "XGBoost        0.6365  0.6716    0.6212  0.6270  0.6582  0.6360  0.6462   \n",
      "\n",
      "                       \n",
      "Conjunto        TRAIN  \n",
      "Modelo                 \n",
      "LightGBM       0.6762  \n",
      "Random Forest  0.7545  \n",
      "XGBoost        0.6857  \n",
      "\n",
      "üèÜ Mejor modelo (por AUC en DEV): Random Forest\n",
      "\n",
      "================================================================================\n",
      "8. AN√ÅLISIS DETALLADO: Random Forest\n",
      "================================================================================\n",
      "\n",
      "üìä Matriz de Confusi√≥n (DEV):\n",
      "\n",
      "                 Predicho: Sin   Predicho: Con\n",
      "Real: Sin anemia      4701          2356\n",
      "Real: Con anemia      2019          4071\n",
      "\n",
      "üìà Classification Report (DEV):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Sin anemia       0.70      0.67      0.68      7057\n",
      "  Con anemia       0.63      0.67      0.65      6090\n",
      "\n",
      "    accuracy                           0.67     13147\n",
      "   macro avg       0.67      0.67      0.67     13147\n",
      "weighted avg       0.67      0.67      0.67     13147\n",
      "\n",
      "\n",
      "üîù Top 15 Features m√°s importantes:\n",
      "Feature  Importance\n",
      "    HC1    0.236238\n",
      "  HV040    0.168049\n",
      "    HW3    0.133917\n",
      "   HC70    0.121612\n",
      "   V012    0.073525\n",
      "  HV024    0.069376\n",
      "   V133    0.061900\n",
      "   BORD    0.040190\n",
      "   V190    0.035450\n",
      "   V106    0.025782\n",
      "   HC27    0.016991\n",
      "  HV025    0.011375\n",
      "  HV237    0.005593\n",
      "\n",
      "================================================================================\n",
      "9. GENERANDO VISUALIZACIONES\n",
      "================================================================================\n",
      "\n",
      "‚úì Gr√°ficos guardados: D:\\Resultados_ML\\comparacion_modelos_20251213_154615.png\n",
      "‚úì Feature importance guardado: D:\\Resultados_ML\\feature_importance_20251213_154620.png\n",
      "\n",
      "================================================================================\n",
      "10. GUARDANDO RESULTADOS\n",
      "================================================================================\n",
      "\n",
      "‚úì Resultados guardados: D:\\Resultados_ML\\resultados_modelos_20251213_154621.xlsx\n",
      "‚úì Mejor modelo guardado: D:\\Resultados_ML\\mejor_modelo_Random_Forest_20251213_154622.pkl\n",
      "\n",
      "================================================================================\n",
      "‚úÖ PROCESO COMPLETADO\n",
      "================================================================================\n",
      "\n",
      "üìÅ Archivos generados en: D:\\Resultados_ML\n",
      "   1. resultados_modelos_20251213_154621.xlsx\n",
      "   2. comparacion_modelos_20251213_154615.png\n",
      "   3. feature_importance_20251213_154620.png\n",
      "   4. mejor_modelo_Random_Forest_20251213_154622.pkl\n",
      "\n",
      "üèÜ Resumen:\n",
      "   Mejor modelo: Random Forest\n",
      "   M√©tricas en DEV:\n",
      "      AUC:       0.7336\n",
      "      F1-Score:  0.6296\n",
      "      Accuracy:  0.6726\n",
      "      Precision: 0.6240\n",
      "      Recall:    0.6352\n",
      "\n",
      "üí° Pr√≥ximos pasos:\n",
      "   1. Revisar archivo Excel con resultados detallados\n",
      "   2. Analizar feature importance para interpretabilidad\n",
      "   3. Considerar ajuste de hiperpar√°metros si es necesario\n",
      "   4. Validar resultados con expertos en salud p√∫blica\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Modelos\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# Preprocesamiento\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "# M√©tricas\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, accuracy_score, precision_score, recall_score, \n",
    "    f1_score, confusion_matrix, classification_report, roc_curve,\n",
    "    precision_recall_curve, average_precision_score\n",
    ")\n",
    "\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"MODELADO MACHINE LEARNING - PREDICCI√ìN DE ANEMIA INFANTIL\")\n",
    "print(\"ENDES 2015-2024 | ESTRATIFICACI√ìN CRUZADA A√ëO √ó ANEMIA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ============================================================\n",
    "# CONFIGURACI√ìN\n",
    "# ============================================================\n",
    "ruta_datos = Path(r\"D:\\Bases_train_test\")\n",
    "ruta_resultados = Path(r\"D:\\Resultados_ML\")\n",
    "ruta_resultados.mkdir(exist_ok=True)\n",
    "\n",
    "# ============================================================\n",
    "# 1. CARGAR DATOS\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"1. CARGANDO DATOS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nCargando datasets...\")\n",
    "df_train = pd.read_csv(ruta_datos / \"endes_train_2015_2024.csv\", encoding='utf-8-sig')\n",
    "df_test = pd.read_csv(ruta_datos / \"endes_test_2015_2024.csv\", encoding='utf-8-sig')\n",
    "df_dev = pd.read_csv(ruta_datos / \"endes_dev_2015_2024.csv\", encoding='utf-8-sig')\n",
    "\n",
    "print(f\"\\n‚úì TRAIN: {len(df_train):,} registros √ó {df_train.shape[1]} columnas\")\n",
    "print(f\"   A√±os: {sorted(df_train['ANIO'].unique())}\")\n",
    "print(f\"   Prevalencia anemia: {df_train['ANEMIA'].mean()*100:.2f}%\")\n",
    "\n",
    "print(f\"\\n‚úì TEST:  {len(df_test):,} registros √ó {df_test.shape[1]} columnas\")\n",
    "print(f\"   A√±os: {sorted(df_test['ANIO'].unique())}\")\n",
    "print(f\"   Prevalencia anemia: {df_test['ANEMIA'].mean()*100:.2f}%\")\n",
    "\n",
    "print(f\"\\n‚úì DEV:   {len(df_dev):,} registros √ó {df_dev.shape[1]} columnas\")\n",
    "print(f\"   A√±os: {sorted(df_dev['ANIO'].unique())}\")\n",
    "print(f\"   Prevalencia anemia: {df_dev['ANEMIA'].mean()*100:.2f}%\")\n",
    "\n",
    "# ============================================================\n",
    "# 2. AN√ÅLISIS EXPLORATORIO INICIAL\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"2. AN√ÅLISIS EXPLORATORIO\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nüìä Distribuci√≥n de ANEMIA por partici√≥n:\")\n",
    "print(f\"\\n{'Partici√≥n':<10} {'Sin anemia':>12} {'Con anemia':>12} {'Total':>10} {'% Anemia':>10}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for nombre, df in [('TRAIN', df_train), ('TEST', df_test), ('DEV', df_dev)]:\n",
    "    sin_anemia = (df['ANEMIA'] == 0).sum()\n",
    "    con_anemia = (df['ANEMIA'] == 1).sum()\n",
    "    total = len(df)\n",
    "    pct = con_anemia / total * 100\n",
    "    print(f\"{nombre:<10} {sin_anemia:>12,} {con_anemia:>12,} {total:>10,} {pct:>9.2f}%\")\n",
    "\n",
    "# Verificar columnas disponibles\n",
    "print(f\"\\nüìã Columnas disponibles: {df_train.shape[1]}\")\n",
    "print(f\"   Primeras 10: {df_train.columns.tolist()[:10]}\")\n",
    "\n",
    "# ============================================================\n",
    "# 3. SELECCI√ìN Y PREPARACI√ìN DE FEATURES\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"3. SELECCI√ìN Y PREPARACI√ìN DE FEATURES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Definir features disponibles\n",
    "features_numericas = [\n",
    "    'HC1',      # Edad en meses\n",
    "    # 'HC53',   # ‚ùå EXCLUIDO - Hemoglobina (DATA LEAKAGE - define anemia)\n",
    "    'HC70',     # Altura/edad Z-score\n",
    "    #'HV009',    # Miembros del hogar\n",
    "    'HV040',    # Altitud\n",
    "   # 'HV271',    # √çndice de riqueza\n",
    "   # 'HW1',      # Edad en meses (REC44)\n",
    "   # 'HW2',      # Peso\n",
    "    'HW3',      # Talla\n",
    "   # 'HW70',     # Talla/Edad Z-score\n",
    "  #  'HW71',     # Peso/Edad Z-score\n",
    "  #  'HW72',     # Peso/Talla Z-score\n",
    "  #  'HW73',     # IMC Z-score\n",
    "    'BORD',     # Orden de nacimiento\n",
    "    'V012',     # Edad de la madre\n",
    "    'V133',     # Educaci√≥n en a√±os\n",
    "   # 'ANIO',     # A√±o (para capturar tendencias temporales)\n",
    "]\n",
    "\n",
    "features_categoricas = [\n",
    "    'HC27',     # Sexo\n",
    "  #  'HC55',     # Resultado de medici√≥n\n",
    "   # 'HC57',     # Nivel de anemia (aunque est√° relacionado con target)\n",
    "    'HV024',    # Regi√≥n/departamento\n",
    "    'HV025',    # √Årea de residencia\n",
    "  #  'HV201',    # Fuente de agua\n",
    "  #  'HV205',    # Tipo de servicio sanitario\n",
    "  #  'HV206',    # Electricidad\n",
    "    'HV237',    # Tratamiento del agua\n",
    "   # 'V025',     # √Årea de residencia (madre)\n",
    "    'V106',     # Nivel educativo madre\n",
    "    'V190',     # √çndice de riqueza (categorizado)\n",
    "]\n",
    "\n",
    "# Verificar qu√© features est√°n disponibles\n",
    "features_numericas_disponibles = [f for f in features_numericas if f in df_train.columns]\n",
    "features_categoricas_disponibles = [f for f in features_categoricas if f in df_train.columns]\n",
    "\n",
    "# EXCLUIR HC57 porque es derivado directo del target\n",
    "if 'HC57' in features_categoricas_disponibles:\n",
    "    features_categoricas_disponibles.remove('HC57')\n",
    "    print(f\"\\n‚ö†Ô∏è  HC57 excluido (derivado directo del target)\")\n",
    "\n",
    "print(f\"\\n‚úì Features num√©ricas disponibles: {len(features_numericas_disponibles)}\")\n",
    "print(f\"   {features_numericas_disponibles}\")\n",
    "\n",
    "print(f\"\\n‚úì Features categ√≥ricas disponibles: {len(features_categoricas_disponibles)}\")\n",
    "print(f\"   {features_categoricas_disponibles}\")\n",
    "\n",
    "# Combinar features\n",
    "features = features_numericas_disponibles + features_categoricas_disponibles\n",
    "print(f\"\\n‚úì Total features: {len(features)}\")\n",
    "\n",
    "# ============================================================\n",
    "# 4. PREPROCESAMIENTO\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"4. PREPROCESAMIENTO\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def preprocesar_datos(df, features_num, features_cat, le_dict=None, fit=True):\n",
    "    \"\"\"\n",
    "    Preprocesa los datos:\n",
    "    - Imputa missings en num√©ricas con mediana\n",
    "    - Codifica categ√≥ricas con LabelEncoder\n",
    "    \"\"\"\n",
    "    df_prep = df.copy()\n",
    "    \n",
    "    # 1. Imputar num√©ricas con mediana\n",
    "    for col in features_num:\n",
    "        if col in df_prep.columns:\n",
    "            if df_prep[col].isna().any():\n",
    "                mediana = df_prep[col].median()\n",
    "                df_prep[col].fillna(mediana, inplace=True)\n",
    "    \n",
    "    # 2. Codificar categ√≥ricas\n",
    "    if le_dict is None:\n",
    "        le_dict = {}\n",
    "    \n",
    "    for col in features_cat:\n",
    "        if col in df_prep.columns:\n",
    "            # Convertir a string y manejar missings\n",
    "            df_prep[col] = df_prep[col].astype(str).fillna('missing')\n",
    "            \n",
    "            if fit:\n",
    "                # Crear y ajustar LabelEncoder\n",
    "                le = LabelEncoder()\n",
    "                df_prep[col] = le.fit_transform(df_prep[col])\n",
    "                le_dict[col] = le\n",
    "            else:\n",
    "                # Usar LabelEncoder existente\n",
    "                le = le_dict[col]\n",
    "                # Manejar categor√≠as no vistas\n",
    "                df_prep[col] = df_prep[col].apply(\n",
    "                    lambda x: x if x in le.classes_ else 'missing'\n",
    "                )\n",
    "                # A√±adir 'missing' si no est√° en classes_\n",
    "                if 'missing' not in le.classes_:\n",
    "                    le.classes_ = np.append(le.classes_, 'missing')\n",
    "                df_prep[col] = le.transform(df_prep[col])\n",
    "    \n",
    "    return df_prep, le_dict\n",
    "\n",
    "# Preprocesar TRAIN\n",
    "print(\"\\nPreprocesando TRAIN...\")\n",
    "df_train_prep, label_encoders = preprocesar_datos(\n",
    "    df_train, \n",
    "    features_numericas_disponibles, \n",
    "    features_categoricas_disponibles,\n",
    "    fit=True\n",
    ")\n",
    "\n",
    "# Preprocesar TEST\n",
    "print(\"Preprocesando TEST...\")\n",
    "df_test_prep, _ = preprocesar_datos(\n",
    "    df_test,\n",
    "    features_numericas_disponibles,\n",
    "    features_categoricas_disponibles,\n",
    "    le_dict=label_encoders,\n",
    "    fit=False\n",
    ")\n",
    "\n",
    "# Preprocesar DEV\n",
    "print(\"Preprocesando DEV...\")\n",
    "df_dev_prep, _ = preprocesar_datos(\n",
    "    df_dev,\n",
    "    features_numericas_disponibles,\n",
    "    features_categoricas_disponibles,\n",
    "    le_dict=label_encoders,\n",
    "    fit=False\n",
    ")\n",
    "\n",
    "# Extraer X e y\n",
    "X_train = df_train_prep[features]\n",
    "y_train = df_train_prep['ANEMIA']\n",
    "\n",
    "X_test = df_test_prep[features]\n",
    "y_test = df_test_prep['ANEMIA']\n",
    "\n",
    "X_dev = df_dev_prep[features]\n",
    "y_dev = df_dev_prep['ANEMIA']\n",
    "\n",
    "# Usar pesos muestrales si est√° disponible\n",
    "if 'PESO' in df_train.columns:\n",
    "    # Limpiar NaN en pesos y normalizar\n",
    "    w_train = df_train['PESO'].fillna(df_train['PESO'].median())\n",
    "    w_test = df_test['PESO'].fillna(df_test['PESO'].median())\n",
    "    w_dev = df_dev['PESO'].fillna(df_dev['PESO'].median())\n",
    "    \n",
    "    # Verificar que no haya NaN\n",
    "    if w_train.isna().any() or w_test.isna().any() or w_dev.isna().any():\n",
    "        print(f\"\\n‚ö†Ô∏è  Pesos con NaN despu√©s de imputaci√≥n, no se usar√°n pesos\")\n",
    "        w_train = None\n",
    "        w_test = None\n",
    "        w_dev = None\n",
    "        usar_pesos = False\n",
    "    else:\n",
    "        usar_pesos = True\n",
    "        print(f\"\\n‚úì Usando pesos muestrales (variable PESO)\")\n",
    "        print(f\"   Rango TRAIN: {w_train.min():.6f} - {w_train.max():.6f}\")\n",
    "else:\n",
    "    w_train = None\n",
    "    w_test = None\n",
    "    w_dev = None\n",
    "    usar_pesos = False\n",
    "    print(f\"\\n‚ö†Ô∏è  No se encontr√≥ variable PESO, no se usar√°n pesos muestrales\")\n",
    "\n",
    "print(f\"\\n‚úì Preparaci√≥n completada:\")\n",
    "print(f\"   X_train: {X_train.shape}\")\n",
    "print(f\"   X_test:  {X_test.shape}\")\n",
    "print(f\"   X_dev:   {X_dev.shape}\")\n",
    "\n",
    "# Verificar missings\n",
    "print(f\"\\nüîç Verificando missings en X_train:\")\n",
    "missings = X_train.isna().sum().sum()\n",
    "if missings > 0:\n",
    "    print(f\"   ‚ö†Ô∏è  {missings} missings encontrados\")\n",
    "    print(X_train.isna().sum()[X_train.isna().sum() > 0])\n",
    "else:\n",
    "    print(f\"   ‚úì Sin missings\")\n",
    "\n",
    "# ============================================================\n",
    "# 5. DEFINICI√ìN DE MODELOS\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"5. DEFINICI√ìN DE MODELOS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "modelos = {\n",
    "    'Random Forest': RandomForestClassifier(\n",
    "        n_estimators=200,\n",
    "        max_depth=15,\n",
    "        min_samples_split=20,\n",
    "        min_samples_leaf=10,\n",
    "        max_features='sqrt',\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        class_weight='balanced'\n",
    "    ),\n",
    "    \n",
    "    'XGBoost': XGBClassifier(\n",
    "        n_estimators=200,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.05,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        scale_pos_weight=(y_train == 0).sum() / (y_train == 1).sum()\n",
    "    ),\n",
    "    \n",
    "    'LightGBM': LGBMClassifier(\n",
    "        n_estimators=200,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.05,\n",
    "        num_leaves=31,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        class_weight='balanced',\n",
    "        verbosity=-1\n",
    "    )\n",
    "}\n",
    "\n",
    "print(f\"\\n‚úì Modelos definidos:\")\n",
    "for nombre in modelos.keys():\n",
    "    print(f\"   ‚Ä¢ {nombre}\")\n",
    "\n",
    "# ============================================================\n",
    "# 6. ENTRENAMIENTO Y EVALUACI√ìN\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"6. ENTRENAMIENTO Y EVALUACI√ìN\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def evaluar_modelo(y_true, y_pred, y_pred_proba, conjunto, peso=None):\n",
    "    \"\"\"Calcula m√©tricas de evaluaci√≥n\"\"\"\n",
    "    \n",
    "    # Si hay pesos, calcular m√©tricas ponderadas\n",
    "    sample_weight = peso if peso is not None else None\n",
    "    \n",
    "    metricas = {\n",
    "        'Conjunto': conjunto,\n",
    "        'Accuracy': accuracy_score(y_true, y_pred, sample_weight=sample_weight),\n",
    "        'Precision': precision_score(y_true, y_pred, sample_weight=sample_weight, zero_division=0),\n",
    "        'Recall': recall_score(y_true, y_pred, sample_weight=sample_weight, zero_division=0),\n",
    "        'F1': f1_score(y_true, y_pred, sample_weight=sample_weight, zero_division=0),\n",
    "        'AUC': roc_auc_score(y_true, y_pred_proba, sample_weight=sample_weight),\n",
    "        'AP': average_precision_score(y_true, y_pred_proba, sample_weight=sample_weight)\n",
    "    }\n",
    "    \n",
    "    return metricas\n",
    "\n",
    "resultados = []\n",
    "modelos_entrenados = {}\n",
    "\n",
    "for nombre_modelo, modelo in modelos.items():\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Entrenando: {nombre_modelo}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Entrenar\n",
    "    print(f\"\\n‚è≥ Entrenando en TRAIN...\")\n",
    "    if usar_pesos:\n",
    "        modelo.fit(X_train, y_train, sample_weight=w_train)\n",
    "    else:\n",
    "        modelo.fit(X_train, y_train)\n",
    "    \n",
    "    # Guardar modelo entrenado\n",
    "    modelos_entrenados[nombre_modelo] = modelo\n",
    "    \n",
    "    # Predicciones en TRAIN\n",
    "    print(f\"üìä Evaluando en TRAIN...\")\n",
    "    y_train_pred = modelo.predict(X_train)\n",
    "    y_train_proba = modelo.predict_proba(X_train)[:, 1]\n",
    "    metricas_train = evaluar_modelo(y_train, y_train_pred, y_train_proba, 'TRAIN', w_train if usar_pesos else None)\n",
    "    metricas_train['Modelo'] = nombre_modelo\n",
    "    \n",
    "    # Predicciones en TEST\n",
    "    print(f\"üìä Evaluando en TEST...\")\n",
    "    y_test_pred = modelo.predict(X_test)\n",
    "    y_test_proba = modelo.predict_proba(X_test)[:, 1]\n",
    "    metricas_test = evaluar_modelo(y_test, y_test_pred, y_test_proba, 'TEST', w_test if usar_pesos else None)\n",
    "    metricas_test['Modelo'] = nombre_modelo\n",
    "    \n",
    "    # Predicciones en DEV\n",
    "    print(f\"üìä Evaluando en DEV...\")\n",
    "    y_dev_pred = modelo.predict(X_dev)\n",
    "    y_dev_proba = modelo.predict_proba(X_dev)[:, 1]\n",
    "    metricas_dev = evaluar_modelo(y_dev, y_dev_pred, y_dev_proba, 'DEV', w_dev if usar_pesos else None)\n",
    "    metricas_dev['Modelo'] = nombre_modelo\n",
    "    \n",
    "    # Agregar resultados\n",
    "    resultados.extend([metricas_train, metricas_test, metricas_dev])\n",
    "    \n",
    "    # Mostrar resumen\n",
    "    print(f\"\\n‚úì {nombre_modelo} - Resumen:\")\n",
    "    print(f\"   TRAIN ‚Üí AUC: {metricas_train['AUC']:.4f}, F1: {metricas_train['F1']:.4f}\")\n",
    "    print(f\"   TEST  ‚Üí AUC: {metricas_test['AUC']:.4f}, F1: {metricas_test['F1']:.4f}\")\n",
    "    print(f\"   DEV   ‚Üí AUC: {metricas_dev['AUC']:.4f}, F1: {metricas_dev['F1']:.4f}\")\n",
    "\n",
    "# ============================================================\n",
    "# 7. COMPARACI√ìN DE MODELOS\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"7. COMPARACI√ìN DE MODELOS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "df_resultados = pd.DataFrame(resultados)\n",
    "\n",
    "# Pivot para mejor visualizaci√≥n\n",
    "df_pivot = df_resultados.pivot_table(\n",
    "    index='Modelo',\n",
    "    columns='Conjunto',\n",
    "    values=['AUC', 'F1', 'Accuracy', 'Precision', 'Recall']\n",
    ")\n",
    "\n",
    "print(f\"\\nüìä Tabla comparativa de modelos:\")\n",
    "print(df_pivot.round(4))\n",
    "\n",
    "# Identificar mejor modelo (por AUC en DEV)\n",
    "mejor_modelo_nombre = df_resultados[df_resultados['Conjunto'] == 'DEV'].sort_values('AUC', ascending=False).iloc[0]['Modelo']\n",
    "print(f\"\\nüèÜ Mejor modelo (por AUC en DEV): {mejor_modelo_nombre}\")\n",
    "\n",
    "mejor_modelo = modelos_entrenados[mejor_modelo_nombre]\n",
    "\n",
    "# ============================================================\n",
    "# 8. AN√ÅLISIS DETALLADO DEL MEJOR MODELO\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"8. AN√ÅLISIS DETALLADO: {mejor_modelo_nombre}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Matriz de confusi√≥n en DEV\n",
    "y_dev_pred_mejor = mejor_modelo.predict(X_dev)\n",
    "cm = confusion_matrix(y_dev, y_dev_pred_mejor)\n",
    "\n",
    "print(f\"\\nüìä Matriz de Confusi√≥n (DEV):\")\n",
    "print(f\"\\n                 Predicho: Sin   Predicho: Con\")\n",
    "print(f\"Real: Sin anemia    {cm[0,0]:>6}        {cm[0,1]:>6}\")\n",
    "print(f\"Real: Con anemia    {cm[1,0]:>6}        {cm[1,1]:>6}\")\n",
    "\n",
    "print(f\"\\nüìà Classification Report (DEV):\")\n",
    "print(classification_report(y_dev, y_dev_pred_mejor, target_names=['Sin anemia', 'Con anemia']))\n",
    "\n",
    "# Feature importance (si el modelo lo soporta)\n",
    "if hasattr(mejor_modelo, 'feature_importances_'):\n",
    "    print(f\"\\nüîù Top 15 Features m√°s importantes:\")\n",
    "    importances = pd.DataFrame({\n",
    "        'Feature': features,\n",
    "        'Importance': mejor_modelo.feature_importances_\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    print(importances.head(15).to_string(index=False))\n",
    "\n",
    "# ============================================================\n",
    "# 9. VISUALIZACIONES\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"9. GENERANDO VISUALIZACIONES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Configurar estilo\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Comparaci√≥n de AUC por modelo\n",
    "ax = axes[0, 0]\n",
    "df_auc = df_resultados.pivot(index='Modelo', columns='Conjunto', values='AUC')\n",
    "df_auc.plot(kind='bar', ax=ax, rot=0)\n",
    "ax.set_title('Comparaci√≥n AUC por Modelo y Conjunto', fontsize=14, fontweight='bold')\n",
    "ax.set_ylabel('AUC', fontsize=12)\n",
    "ax.set_xlabel('Modelo', fontsize=12)\n",
    "ax.legend(title='Conjunto', fontsize=10)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "ax.set_ylim([0.5, 1.0])\n",
    "\n",
    "# 2. Comparaci√≥n de F1 por modelo\n",
    "ax = axes[0, 1]\n",
    "df_f1 = df_resultados.pivot(index='Modelo', columns='Conjunto', values='F1')\n",
    "df_f1.plot(kind='bar', ax=ax, rot=0)\n",
    "ax.set_title('Comparaci√≥n F1-Score por Modelo y Conjunto', fontsize=14, fontweight='bold')\n",
    "ax.set_ylabel('F1-Score', fontsize=12)\n",
    "ax.set_xlabel('Modelo', fontsize=12)\n",
    "ax.legend(title='Conjunto', fontsize=10)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "ax.set_ylim([0, 1.0])\n",
    "\n",
    "# 3. Curva ROC del mejor modelo\n",
    "ax = axes[1, 0]\n",
    "for conjunto, X, y, color in [('TRAIN', X_train, y_train, 'blue'),\n",
    "                               ('TEST', X_test, y_test, 'orange'),\n",
    "                               ('DEV', X_dev, y_dev, 'green')]:\n",
    "    y_proba = mejor_modelo.predict_proba(X)[:, 1]\n",
    "    fpr, tpr, _ = roc_curve(y, y_proba)\n",
    "    auc_val = roc_auc_score(y, y_proba)\n",
    "    ax.plot(fpr, tpr, label=f'{conjunto} (AUC={auc_val:.3f})', color=color, linewidth=2)\n",
    "\n",
    "ax.plot([0, 1], [0, 1], 'k--', label='Random', linewidth=1)\n",
    "ax.set_title(f'Curva ROC - {mejor_modelo_nombre}', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('False Positive Rate', fontsize=12)\n",
    "ax.set_ylabel('True Positive Rate', fontsize=12)\n",
    "ax.legend(fontsize=10)\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "# 4. Matriz de confusi√≥n del mejor modelo en DEV\n",
    "ax = axes[1, 1]\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax, \n",
    "            xticklabels=['Sin anemia', 'Con anemia'],\n",
    "            yticklabels=['Sin anemia', 'Con anemia'],\n",
    "            cbar_kws={'label': 'Cantidad'})\n",
    "ax.set_title(f'Matriz de Confusi√≥n (DEV) - {mejor_modelo_nombre}', fontsize=14, fontweight='bold')\n",
    "ax.set_ylabel('Real', fontsize=12)\n",
    "ax.set_xlabel('Predicho', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "archivo_grafico = ruta_resultados / f\"comparacion_modelos_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png\"\n",
    "plt.savefig(archivo_grafico, dpi=300, bbox_inches='tight')\n",
    "print(f\"\\n‚úì Gr√°ficos guardados: {archivo_grafico}\")\n",
    "plt.close()\n",
    "\n",
    "# Gr√°fico adicional: Feature Importance\n",
    "if hasattr(mejor_modelo, 'feature_importances_'):\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    importances_top20 = importances.head(20)\n",
    "    ax.barh(importances_top20['Feature'], importances_top20['Importance'])\n",
    "    ax.set_xlabel('Importancia', fontsize=12)\n",
    "    ax.set_title(f'Top 20 Features - {mejor_modelo_nombre}', fontsize=14, fontweight='bold')\n",
    "    ax.invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    archivo_importance = ruta_resultados / f\"feature_importance_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png\"\n",
    "    plt.savefig(archivo_importance, dpi=300, bbox_inches='tight')\n",
    "    print(f\"‚úì Feature importance guardado: {archivo_importance}\")\n",
    "    plt.close()\n",
    "\n",
    "# ============================================================\n",
    "# 10. GUARDAR RESULTADOS\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"10. GUARDANDO RESULTADOS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Guardar tabla de resultados\n",
    "archivo_resultados = ruta_resultados / f\"resultados_modelos_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx\"\n",
    "\n",
    "with pd.ExcelWriter(archivo_resultados, engine='openpyxl') as writer:\n",
    "    # Hoja 1: Resultados detallados\n",
    "    df_resultados.to_excel(writer, sheet_name='Resultados_Detallados', index=False)\n",
    "    \n",
    "    # Hoja 2: Comparaci√≥n (pivot)\n",
    "    df_pivot.to_excel(writer, sheet_name='Comparacion')\n",
    "    \n",
    "    # Hoja 3: Feature importance (si existe)\n",
    "    if hasattr(mejor_modelo, 'feature_importances_'):\n",
    "        importances.to_excel(writer, sheet_name='Feature_Importance', index=False)\n",
    "    \n",
    "    # Hoja 4: Confusion Matrix\n",
    "    cm_df = pd.DataFrame(cm, \n",
    "                         index=['Real: Sin anemia', 'Real: Con anemia'],\n",
    "                         columns=['Pred: Sin anemia', 'Pred: Con anemia'])\n",
    "    cm_df.to_excel(writer, sheet_name='Confusion_Matrix')\n",
    "\n",
    "print(f\"\\n‚úì Resultados guardados: {archivo_resultados}\")\n",
    "\n",
    "# Guardar mejor modelo\n",
    "archivo_modelo = ruta_resultados / f\"mejor_modelo_{mejor_modelo_nombre.replace(' ', '_')}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pkl\"\n",
    "with open(archivo_modelo, 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'modelo': mejor_modelo,\n",
    "        'label_encoders': label_encoders,\n",
    "        'features': features,\n",
    "        'features_numericas': features_numericas_disponibles,\n",
    "        'features_categoricas': features_categoricas_disponibles\n",
    "    }, f)\n",
    "\n",
    "print(f\"‚úì Mejor modelo guardado: {archivo_modelo}\")\n",
    "\n",
    "# ============================================================\n",
    "# RESUMEN FINAL\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ PROCESO COMPLETADO\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nüìÅ Archivos generados en: {ruta_resultados}\")\n",
    "print(f\"   1. {archivo_resultados.name}\")\n",
    "print(f\"   2. {archivo_grafico.name}\")\n",
    "if hasattr(mejor_modelo, 'feature_importances_'):\n",
    "    print(f\"   3. {archivo_importance.name}\")\n",
    "print(f\"   4. {archivo_modelo.name}\")\n",
    "\n",
    "print(f\"\\nüèÜ Resumen:\")\n",
    "print(f\"   Mejor modelo: {mejor_modelo_nombre}\")\n",
    "metricas_dev_mejor = df_resultados[(df_resultados['Modelo'] == mejor_modelo_nombre) & \n",
    "                                   (df_resultados['Conjunto'] == 'DEV')].iloc[0]\n",
    "print(f\"   M√©tricas en DEV:\")\n",
    "print(f\"      AUC:       {metricas_dev_mejor['AUC']:.4f}\")\n",
    "print(f\"      F1-Score:  {metricas_dev_mejor['F1']:.4f}\")\n",
    "print(f\"      Accuracy:  {metricas_dev_mejor['Accuracy']:.4f}\")\n",
    "print(f\"      Precision: {metricas_dev_mejor['Precision']:.4f}\")\n",
    "print(f\"      Recall:    {metricas_dev_mejor['Recall']:.4f}\")\n",
    "\n",
    "print(f\"\\nüí° Pr√≥ximos pasos:\")\n",
    "print(f\"   1. Revisar archivo Excel con resultados detallados\")\n",
    "print(f\"   2. Analizar feature importance para interpretabilidad\")\n",
    "print(f\"   3. Considerar ajuste de hiperpar√°metros si es necesario\")\n",
    "print(f\"   4. Validar resultados con expertos en salud p√∫blica\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ba9926-e597-4642-a8bf-28b997f867fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9f8bd0-b968-43fd-9c63-6a12edf4bf1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac507a07-8d18-44b8-9922-bc4778ee5d94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35972c94-4fdf-4dfa-8eba-aeed7ba183c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "OPTIMIZACI√ìN AVANZADA - PREDICCI√ìN DE ANEMIA INFANTIL\n",
      "Sin HC53 (hemoglobina) para evitar data leakage\n",
      "Versi√≥n Corregida con Ajuste Autom√°tico de SMOTE\n",
      "================================================================================\n",
      "\n",
      "1. CARGANDO DATOS...\n",
      "\n",
      "‚úì Datos preparados: 17 features\n",
      "   X_train: (92030, 17)\n",
      "\n",
      "üìä Distribuci√≥n de clases en TRAIN:\n",
      "   Clase 0 (Sin anemia): 49,391 (53.67%)\n",
      "   Clase 1 (Con anemia): 42,639 (46.33%)\n",
      "   Ratio actual (minoritaria/mayoritaria): 0.8633\n",
      "\n",
      "================================================================================\n",
      "2. ESTRATEGIA 1: AJUSTE DE THRESHOLD PARA MAXIMIZAR RECALL\n",
      "================================================================================\n",
      "\n",
      "‚è≥ Entrenando LightGBM base...\n",
      "\n",
      "üîç Probando diferentes thresholds en TEST:\n",
      "\n",
      " Threshold   Recall  Precision       F1   Accuracy\n",
      "------------------------------------------------------------\n",
      "      0.30   0.9021     0.5388   0.6746     0.5969\n",
      "      0.32   0.8849     0.5478   0.6767     0.6082\n",
      "      0.34   0.8678     0.5570   0.6785     0.6190\n",
      "      0.36   0.8497     0.5653   0.6789     0.6277\n",
      "      0.38   0.8304     0.5749   0.6794     0.6369\n",
      "      0.40   0.8113     0.5844   0.6794     0.6452\n",
      "      0.42   0.7886     0.5927   0.6768     0.6510\n",
      "      0.44   0.7634     0.6024   0.6734     0.6570\n",
      "      0.46   0.7365     0.6106   0.6676     0.6603\n",
      "      0.48   0.7117     0.6210   0.6633     0.6652\n",
      "      0.50   0.6834     0.6308   0.6561     0.6681\n",
      "      0.52   0.6536     0.6421   0.6478     0.6707\n",
      "      0.54   0.6204     0.6539   0.6367     0.6720\n",
      "      0.56   0.5860     0.6665   0.6237     0.6724\n",
      "      0.58   0.5493     0.6794   0.6075     0.6711\n",
      "      0.60   0.5089     0.6917   0.5864     0.6674\n",
      "      0.62   0.4643     0.7026   0.5591     0.6608\n",
      "      0.64   0.4177     0.7134   0.5268     0.6525\n",
      "      0.66   0.3700     0.7284   0.4907     0.6442\n",
      "      0.68   0.3236     0.7440   0.4510     0.6350\n",
      "\n",
      "‚úì Mejor threshold: 0.38 (F1=0.6794, Recall=0.8304)\n",
      "\n",
      "üìä Resultados en DEV con threshold optimizado (0.38):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Sin anemia       0.76      0.46      0.57      7057\n",
      "  Con anemia       0.57      0.84      0.68      6090\n",
      "\n",
      "    accuracy                           0.63     13147\n",
      "   macro avg       0.67      0.65      0.63     13147\n",
      "weighted avg       0.68      0.63      0.62     13147\n",
      "\n",
      "\n",
      "================================================================================\n",
      "3. ESTRATEGIA 2: BALANCEO CON SMOTE + UNDERSAMPLING\n",
      "================================================================================\n",
      "\n",
      "üìä Configuraci√≥n de balanceo:\n",
      "   Ratio actual: 0.8633\n",
      "   Ratio objetivo SMOTE: 0.9000\n",
      "\n",
      "‚è≥ Aplicando SMOTE...\n",
      "\n",
      "‚úì Balanceo aplicado:\n",
      "   Antes: {0.0: 49391, 1.0: 42639}\n",
      "   Despu√©s: {0.0: 49391, 1.0: 44451}\n",
      "   Nuevo ratio: 0.9000\n",
      "\n",
      "‚è≥ Entrenando LightGBM con datos balanceados...\n",
      "\n",
      "üìä Resultados en DEV con datos balanceados:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Sin anemia       0.69      0.69      0.69      7057\n",
      "  Con anemia       0.64      0.64      0.64      6090\n",
      "\n",
      "    accuracy                           0.67     13147\n",
      "   macro avg       0.67      0.67      0.67     13147\n",
      "weighted avg       0.67      0.67      0.67     13147\n",
      "\n",
      "\n",
      "================================================================================\n",
      "4. ESTRATEGIA 3: CLASS WEIGHT M√ÅS AGRESIVO\n",
      "================================================================================\n",
      "\n",
      "‚öôÔ∏è  Pesos de clase personalizados:\n",
      "   Clase 0 (Sin anemia): 1.00\n",
      "   Clase 1 (Con anemia): 1.74\n",
      "\n",
      "‚è≥ Entrenando modelo con pesos personalizados...\n",
      "\n",
      "üìä Resultados en DEV con class weights personalizados:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Sin anemia       0.75      0.49      0.59      7057\n",
      "  Con anemia       0.58      0.81      0.67      6090\n",
      "\n",
      "    accuracy                           0.64     13147\n",
      "   macro avg       0.66      0.65      0.63     13147\n",
      "weighted avg       0.67      0.64      0.63     13147\n",
      "\n",
      "\n",
      "================================================================================\n",
      "5. ESTRATEGIA 4: HYPERPARAMETER TUNING (GridSearchCV)\n",
      "================================================================================\n",
      "\n",
      "‚è≥ Buscando mejores hiperpar√°metros...\n",
      "Fitting 3 folds for each of 288 candidates, totalling 864 fits\n",
      "\n",
      "‚úì Mejores par√°metros encontrados:\n",
      "   colsample_bytree: 0.8\n",
      "   learning_rate: 0.05\n",
      "   max_depth: 6\n",
      "   min_child_samples: 20\n",
      "   n_estimators: 300\n",
      "   num_leaves: 31\n",
      "   subsample: 0.7\n",
      "\n",
      "üìä Resultados en DEV con hiperpar√°metros optimizados:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Sin anemia       0.70      0.64      0.67      7057\n",
      "  Con anemia       0.62      0.68      0.65      6090\n",
      "\n",
      "    accuracy                           0.66     13147\n",
      "   macro avg       0.66      0.66      0.66     13147\n",
      "weighted avg       0.66      0.66      0.66     13147\n",
      "\n",
      "\n",
      "================================================================================\n",
      "6. COMPARACI√ìN DE ESTRATEGIAS\n",
      "================================================================================\n",
      "\n",
      "üìä Tabla comparativa (ordenada por Recall):\n",
      "             Estrategia   Recall  Precision       F1      AUC  Accuracy\n",
      "   Threshold Optimizado 0.835961   0.571958 0.679208 0.722766  0.634213\n",
      "Class Weights Agresivos 0.807718   0.578230 0.673974 0.722171  0.638016\n",
      "   Base (threshold=0.5) 0.680952   0.623422 0.650918 0.722766  0.661672\n",
      "  Hyperparameter Tuning 0.678818   0.622403 0.649387 0.722003  0.660455\n",
      "      Datos Balanceados 0.640722   0.642728 0.641724 0.726040  0.668594\n",
      "\n",
      "üìä Detalle de matriz de confusi√≥n:\n",
      "             Estrategia   TP   FN   FP   TN\n",
      "   Threshold Optimizado 5091  999 3810 3247\n",
      "Class Weights Agresivos 4919 1171 3588 3469\n",
      "   Base (threshold=0.5) 4147 1943 2505 4552\n",
      "  Hyperparameter Tuning 4134 1956 2508 4549\n",
      "      Datos Balanceados 3902 2188 2169 4888\n",
      "\n",
      "üèÜ Mejor estrategia por RECALL: Threshold Optimizado\n",
      "   Recall: 0.8360\n",
      "   F1: 0.6792\n",
      "\n",
      "ü•à Mejor estrategia por F1: Threshold Optimizado\n",
      "   F1: 0.6792\n",
      "   Recall: 0.8360\n",
      "\n",
      "================================================================================\n",
      "7. FEATURE IMPORTANCE DEL MEJOR MODELO\n",
      "================================================================================\n",
      "\n",
      "üîù Top 15 Features m√°s importantes:\n",
      "Feature  Importance\n",
      "  HV040        2302\n",
      "   HC70        2192\n",
      "   V012        1354\n",
      "    HC1        1339\n",
      "  HV024        1301\n",
      "    HW3        1200\n",
      "    HW2        1171\n",
      "   V133        1001\n",
      "   BORD         811\n",
      "    HW1         695\n",
      "   V190         624\n",
      "   HC27         322\n",
      "   V106         132\n",
      "  HV237         109\n",
      "  HV025          89\n",
      "\n",
      "================================================================================\n",
      "8. GUARDANDO RESULTADOS\n",
      "================================================================================\n",
      "\n",
      "‚úì Resultados guardados: D:\\Resultados_ML\\Optimizado\\comparacion_estrategias_20251112_222731.xlsx\n",
      "‚úì Modelo optimizado guardado: D:\\Resultados_ML\\Optimizado\\modelo_optimizado_20251112_222731.pkl\n",
      "\n",
      "================================================================================\n",
      "‚úÖ OPTIMIZACI√ìN COMPLETADA\n",
      "================================================================================\n",
      "\n",
      "üìä RESUMEN EJECUTIVO:\n",
      "\n",
      "üéØ OBJETIVO: Maximizar RECALL (identificar ni√±os con anemia)\n",
      "\n",
      "üèÜ MEJOR ESTRATEGIA POR RECALL:\n",
      "   Nombre: Threshold Optimizado\n",
      "   Recall: 0.8360 (83.60%)\n",
      "   Precision: 0.5720\n",
      "   F1: 0.6792\n",
      "   AUC: 0.7228\n",
      "\n",
      "ü•à MEJOR ESTRATEGIA BALANCEADA (F1):\n",
      "   Nombre: Threshold Optimizado\n",
      "   F1: 0.6792\n",
      "   Recall: 0.8360\n",
      "   Precision: 0.5720\n",
      "\n",
      "üí° INTERPRETACI√ìN:\n",
      "   - Threshold Optimizado: Ajusta punto de corte para priorizar recall\n",
      "   - Datos Balanceados: Genera muestras sint√©ticas para equilibrar clases\n",
      "   - Class Weights: Penaliza m√°s errores en clase minoritaria\n",
      "   \n",
      "üìÅ ARCHIVOS GENERADOS:\n",
      "   - comparacion_estrategias_20251112_222731.xlsx\n",
      "   - modelo_optimizado_20251112_222731.pkl\n",
      "\n",
      "üî¨ PR√ìXIMOS PASOS:\n",
      "   1. Revisar matrices de confusi√≥n por estrategia\n",
      "   2. Validar interpretabilidad de features importantes\n",
      "   3. Evaluar en datos 2023-2024 (validaci√≥n temporal)\n",
      "   4. Considerar ensemble de mejores modelos\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, f1_score, classification_report, \n",
    "    confusion_matrix, make_scorer, accuracy_score,\n",
    "    recall_score, precision_score\n",
    ")\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"OPTIMIZACI√ìN AVANZADA - PREDICCI√ìN DE ANEMIA INFANTIL\")\n",
    "print(\"Sin HC53 (hemoglobina) para evitar data leakage\")\n",
    "print(\"Versi√≥n Corregida con Ajuste Autom√°tico de SMOTE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ============================================================\n",
    "# CONFIGURACI√ìN\n",
    "# ============================================================\n",
    "ruta_datos = Path(r\"D:\\Bases_train_test\")\n",
    "ruta_resultados = Path(r\"D:\\Resultados_ML\\Optimizado\")\n",
    "ruta_resultados.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# ============================================================\n",
    "# 1. CARGAR Y PREPARAR DATOS\n",
    "# ============================================================\n",
    "print(\"\\n1. CARGANDO DATOS...\")\n",
    "\n",
    "df_train = pd.read_csv(ruta_datos / \"endes_train_2015_2024.csv\")\n",
    "df_test = pd.read_csv(ruta_datos / \"endes_test_2015_2024.csv\")\n",
    "df_dev = pd.read_csv(ruta_datos / \"endes_dev_2015_2024.csv\")\n",
    "\n",
    "# Features (SIN HC53 ni ANIO)\n",
    "features_numericas = [\n",
    "    'HC1', 'HC70', 'HV009', 'HV040', 'HV271',\n",
    "    'HW1', 'HW2', 'HW3',\n",
    "    'BORD', 'V012', 'V133'\n",
    "]\n",
    "\n",
    "features_categoricas = [\n",
    "    'HC27', 'HC55', 'HV024', 'HV025', 'HV237',\n",
    "    'V025', 'V106', 'V190'\n",
    "]\n",
    "\n",
    "# Preprocesamiento\n",
    "def preprocesar(df, features_num, features_cat, le_dict=None, fit=True):\n",
    "    df_prep = df.copy()\n",
    "    \n",
    "    # Imputar num√©ricas\n",
    "    for col in features_num:\n",
    "        if col in df_prep.columns:\n",
    "            df_prep[col].fillna(df_prep[col].median(), inplace=True)\n",
    "    \n",
    "    # Codificar categ√≥ricas\n",
    "    if le_dict is None:\n",
    "        le_dict = {}\n",
    "    \n",
    "    for col in features_cat:\n",
    "        if col in df_prep.columns:\n",
    "            df_prep[col] = df_prep[col].astype(str).fillna('missing')\n",
    "            \n",
    "            if fit:\n",
    "                le = LabelEncoder()\n",
    "                df_prep[col] = le.fit_transform(df_prep[col])\n",
    "                le_dict[col] = le\n",
    "            else:\n",
    "                le = le_dict[col]\n",
    "                df_prep[col] = df_prep[col].apply(\n",
    "                    lambda x: x if x in le.classes_ else 'missing'\n",
    "                )\n",
    "                if 'missing' not in le.classes_:\n",
    "                    le.classes_ = np.append(le.classes_, 'missing')\n",
    "                df_prep[col] = le.transform(df_prep[col])\n",
    "    \n",
    "    return df_prep, le_dict\n",
    "\n",
    "features_num_disp = [f for f in features_numericas if f in df_train.columns]\n",
    "features_cat_disp = [f for f in features_categoricas if f in df_train.columns]\n",
    "features = features_num_disp + features_cat_disp\n",
    "\n",
    "df_train_prep, label_encoders = preprocesar(df_train, features_num_disp, features_cat_disp, fit=True)\n",
    "df_test_prep, _ = preprocesar(df_test, features_num_disp, features_cat_disp, le_dict=label_encoders, fit=False)\n",
    "df_dev_prep, _ = preprocesar(df_dev, features_num_disp, features_cat_disp, le_dict=label_encoders, fit=False)\n",
    "\n",
    "X_train = df_train_prep[features]\n",
    "y_train = df_train_prep['ANEMIA']\n",
    "X_test = df_test_prep[features]\n",
    "y_test = df_test_prep['ANEMIA']\n",
    "X_dev = df_dev_prep[features]\n",
    "y_dev = df_dev_prep['ANEMIA']\n",
    "\n",
    "# Pesos\n",
    "w_train = df_train['PESO'].fillna(df_train['PESO'].median()) if 'PESO' in df_train.columns else None\n",
    "w_test = df_test['PESO'].fillna(df_test['PESO'].median()) if 'PESO' in df_test.columns else None\n",
    "w_dev = df_dev['PESO'].fillna(df_dev['PESO'].median()) if 'PESO' in df_dev.columns else None\n",
    "\n",
    "# An√°lisis de distribuci√≥n de clases\n",
    "print(f\"\\n‚úì Datos preparados: {len(features)} features\")\n",
    "print(f\"   X_train: {X_train.shape}\")\n",
    "print(f\"\\nüìä Distribuci√≥n de clases en TRAIN:\")\n",
    "class_counts = y_train.value_counts()\n",
    "print(f\"   Clase 0 (Sin anemia): {class_counts[0]:,} ({class_counts[0]/len(y_train)*100:.2f}%)\")\n",
    "print(f\"   Clase 1 (Con anemia): {class_counts[1]:,} ({class_counts[1]/len(y_train)*100:.2f}%)\")\n",
    "\n",
    "ratio_actual = class_counts[1] / class_counts[0]\n",
    "print(f\"   Ratio actual (minoritaria/mayoritaria): {ratio_actual:.4f}\")\n",
    "\n",
    "# ============================================================\n",
    "# 2. ESTRATEGIA 1: AJUSTE DE THRESHOLD\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"2. ESTRATEGIA 1: AJUSTE DE THRESHOLD PARA MAXIMIZAR RECALL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Entrenar LightGBM base\n",
    "lgbm_base = LGBMClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=8,\n",
    "    learning_rate=0.03,\n",
    "    num_leaves=50,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    class_weight='balanced',\n",
    "    verbosity=-1\n",
    ")\n",
    "\n",
    "print(\"\\n‚è≥ Entrenando LightGBM base...\")\n",
    "lgbm_base.fit(X_train, y_train, sample_weight=w_train)\n",
    "\n",
    "# Predecir probabilidades\n",
    "y_train_proba = lgbm_base.predict_proba(X_train)[:, 1]\n",
    "y_test_proba = lgbm_base.predict_proba(X_test)[:, 1]\n",
    "y_dev_proba = lgbm_base.predict_proba(X_dev)[:, 1]\n",
    "\n",
    "# Buscar mejor threshold\n",
    "print(\"\\nüîç Probando diferentes thresholds en TEST:\")\n",
    "print(f\"\\n{'Threshold':>10} {'Recall':>8} {'Precision':>10} {'F1':>8} {'Accuracy':>10}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "best_threshold = 0.5\n",
    "best_f1 = 0\n",
    "best_recall = 0\n",
    "\n",
    "resultados_threshold = []\n",
    "\n",
    "for threshold in np.arange(0.3, 0.7, 0.02):\n",
    "    y_test_pred = (y_test_proba >= threshold).astype(int)\n",
    "    \n",
    "    recall = recall_score(y_test, y_test_pred)\n",
    "    precision = precision_score(y_test, y_test_pred, zero_division=0)\n",
    "    f1 = f1_score(y_test, y_test_pred)\n",
    "    acc = accuracy_score(y_test, y_test_pred)\n",
    "    \n",
    "    resultados_threshold.append({\n",
    "        'Threshold': threshold,\n",
    "        'Recall': recall,\n",
    "        'Precision': precision,\n",
    "        'F1': f1,\n",
    "        'Accuracy': acc\n",
    "    })\n",
    "    \n",
    "    print(f\"{threshold:>10.2f} {recall:>8.4f} {precision:>10.4f} {f1:>8.4f} {acc:>10.4f}\")\n",
    "    \n",
    "    # Priorizar recall alto (>0.70) y luego F1\n",
    "    if recall >= 0.70 and f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_threshold = threshold\n",
    "        best_recall = recall\n",
    "\n",
    "print(f\"\\n‚úì Mejor threshold: {best_threshold:.2f} (F1={best_f1:.4f}, Recall={best_recall:.4f})\")\n",
    "\n",
    "# Evaluar en DEV con mejor threshold\n",
    "y_dev_pred_optimal = (y_dev_proba >= best_threshold).astype(int)\n",
    "\n",
    "print(f\"\\nüìä Resultados en DEV con threshold optimizado ({best_threshold:.2f}):\")\n",
    "print(classification_report(y_dev, y_dev_pred_optimal, \n",
    "                          target_names=['Sin anemia', 'Con anemia']))\n",
    "\n",
    "# ============================================================\n",
    "# 3. ESTRATEGIA 2: BALANCEO CON SMOTE (CORREGIDO)\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"3. ESTRATEGIA 2: BALANCEO CON SMOTE + UNDERSAMPLING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Calcular estrategia de balanceo √≥ptima\n",
    "ratio_objetivo = min(0.9, ratio_actual * 1.5)  # Aumentar hasta 90% o 1.5x el ratio actual\n",
    "\n",
    "print(f\"\\nüìä Configuraci√≥n de balanceo:\")\n",
    "print(f\"   Ratio actual: {ratio_actual:.4f}\")\n",
    "print(f\"   Ratio objetivo SMOTE: {ratio_objetivo:.4f}\")\n",
    "\n",
    "if ratio_actual >= 0.9:\n",
    "    print(f\"\\n‚ö†Ô∏è  Las clases ya est√°n bastante balanceadas (ratio={ratio_actual:.4f})\")\n",
    "    print(f\"   Se aplicar√° una estrategia h√≠brida SMOTE + RandomUnderSampler\")\n",
    "    \n",
    "    # Estrategia h√≠brida\n",
    "    over_sampler = SMOTE(sampling_strategy=0.95, random_state=42)\n",
    "    under_sampler = RandomUnderSampler(sampling_strategy=0.9, random_state=42)\n",
    "    \n",
    "    print(f\"\\n‚è≥ Aplicando balanceo h√≠brido...\")\n",
    "    X_train_balanced, y_train_balanced = over_sampler.fit_resample(X_train, y_train)\n",
    "    X_train_balanced, y_train_balanced = under_sampler.fit_resample(X_train_balanced, y_train_balanced)\n",
    "    \n",
    "else:\n",
    "    print(f\"\\n‚è≥ Aplicando SMOTE...\")\n",
    "    smote = SMOTE(sampling_strategy=ratio_objetivo, random_state=42)\n",
    "    X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(f\"\\n‚úì Balanceo aplicado:\")\n",
    "print(f\"   Antes: {y_train.value_counts().to_dict()}\")\n",
    "print(f\"   Despu√©s: {pd.Series(y_train_balanced).value_counts().to_dict()}\")\n",
    "\n",
    "nuevo_ratio = pd.Series(y_train_balanced).value_counts()[1] / pd.Series(y_train_balanced).value_counts()[0]\n",
    "print(f\"   Nuevo ratio: {nuevo_ratio:.4f}\")\n",
    "\n",
    "# Entrenar en datos balanceados\n",
    "print(f\"\\n‚è≥ Entrenando LightGBM con datos balanceados...\")\n",
    "lgbm_balanced = LGBMClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=8,\n",
    "    learning_rate=0.03,\n",
    "    num_leaves=50,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    verbosity=-1\n",
    ")\n",
    "\n",
    "lgbm_balanced.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Evaluar en DEV\n",
    "y_dev_pred_balanced = lgbm_balanced.predict(X_dev)\n",
    "\n",
    "print(f\"\\nüìä Resultados en DEV con datos balanceados:\")\n",
    "print(classification_report(y_dev, y_dev_pred_balanced,\n",
    "                          target_names=['Sin anemia', 'Con anemia']))\n",
    "\n",
    "# ============================================================\n",
    "# 4. ESTRATEGIA 3: CLASS WEIGHT M√ÅS AGRESIVO\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"4. ESTRATEGIA 3: CLASS WEIGHT M√ÅS AGRESIVO\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Calcular pesos personalizados\n",
    "peso_mayoritaria = 1.0\n",
    "peso_minoritaria = class_counts[0] / class_counts[1] * 1.5  # 50% m√°s peso\n",
    "\n",
    "class_weights = {0: peso_mayoritaria, 1: peso_minoritaria}\n",
    "\n",
    "print(f\"\\n‚öôÔ∏è  Pesos de clase personalizados:\")\n",
    "print(f\"   Clase 0 (Sin anemia): {peso_mayoritaria:.2f}\")\n",
    "print(f\"   Clase 1 (Con anemia): {peso_minoritaria:.2f}\")\n",
    "\n",
    "lgbm_weighted = LGBMClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=8,\n",
    "    learning_rate=0.03,\n",
    "    num_leaves=50,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    class_weight=class_weights,\n",
    "    verbosity=-1\n",
    ")\n",
    "\n",
    "print(f\"\\n‚è≥ Entrenando modelo con pesos personalizados...\")\n",
    "lgbm_weighted.fit(X_train, y_train, sample_weight=w_train)\n",
    "\n",
    "y_dev_pred_weighted = lgbm_weighted.predict(X_dev)\n",
    "\n",
    "print(f\"\\nüìä Resultados en DEV con class weights personalizados:\")\n",
    "print(classification_report(y_dev, y_dev_pred_weighted,\n",
    "                          target_names=['Sin anemia', 'Con anemia']))\n",
    "\n",
    "# ============================================================\n",
    "# 5. ESTRATEGIA 4: HYPERPARAMETER TUNING\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"5. ESTRATEGIA 4: HYPERPARAMETER TUNING (GridSearchCV)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n‚è≥ Buscando mejores hiperpar√°metros...\")\n",
    "\n",
    "# Grid m√°s enfocado en recall\n",
    "param_grid = {\n",
    "    'n_estimators': [200, 300],\n",
    "    'max_depth': [6, 8, 10],\n",
    "    'learning_rate': [0.03, 0.05],\n",
    "    'num_leaves': [31, 50],\n",
    "    'min_child_samples': [20, 30, 50],\n",
    "    'subsample': [0.7, 0.8],\n",
    "    'colsample_bytree': [0.7, 0.8]\n",
    "}\n",
    "\n",
    "lgbm_grid = LGBMClassifier(\n",
    "    random_state=42,\n",
    "    class_weight='balanced',\n",
    "    verbosity=-1\n",
    ")\n",
    "\n",
    "# Scorer personalizado que prioriza recall\n",
    "def recall_weighted_scorer(y_true, y_pred):\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    return 0.6 * recall + 0.4 * f1\n",
    "\n",
    "custom_scorer = make_scorer(recall_weighted_scorer)\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    lgbm_grid,\n",
    "    param_grid,\n",
    "    cv=3,\n",
    "    scoring=custom_scorer,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train, sample_weight=w_train)\n",
    "\n",
    "print(f\"\\n‚úì Mejores par√°metros encontrados:\")\n",
    "for param, value in grid_search.best_params_.items():\n",
    "    print(f\"   {param}: {value}\")\n",
    "\n",
    "# Evaluar mejor modelo\n",
    "best_model = grid_search.best_estimator_\n",
    "y_dev_pred_tuned = best_model.predict(X_dev)\n",
    "\n",
    "print(f\"\\nüìä Resultados en DEV con hiperpar√°metros optimizados:\")\n",
    "print(classification_report(y_dev, y_dev_pred_tuned,\n",
    "                          target_names=['Sin anemia', 'Con anemia']))\n",
    "\n",
    "# ============================================================\n",
    "# 6. COMPARACI√ìN FINAL\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"6. COMPARACI√ìN DE ESTRATEGIAS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "estrategias = {\n",
    "    'Base (threshold=0.5)': lgbm_base.predict(X_dev),\n",
    "    'Threshold Optimizado': y_dev_pred_optimal,\n",
    "    'Datos Balanceados': y_dev_pred_balanced,\n",
    "    'Class Weights Agresivos': y_dev_pred_weighted,\n",
    "    'Hyperparameter Tuning': y_dev_pred_tuned\n",
    "}\n",
    "\n",
    "modelos = {\n",
    "    'Base (threshold=0.5)': lgbm_base,\n",
    "    'Threshold Optimizado': lgbm_base,\n",
    "    'Datos Balanceados': lgbm_balanced,\n",
    "    'Class Weights Agresivos': lgbm_weighted,\n",
    "    'Hyperparameter Tuning': best_model\n",
    "}\n",
    "\n",
    "resultados_comparacion = []\n",
    "\n",
    "for nombre, y_pred in estrategias.items():\n",
    "    modelo = modelos[nombre]\n",
    "    \n",
    "    # Obtener probabilidades\n",
    "    if nombre == 'Threshold Optimizado':\n",
    "        y_proba = y_dev_proba\n",
    "    else:\n",
    "        y_proba = modelo.predict_proba(X_dev)[:, 1]\n",
    "    \n",
    "    auc = roc_auc_score(y_dev, y_proba)\n",
    "    f1 = f1_score(y_dev, y_pred)\n",
    "    acc = accuracy_score(y_dev, y_pred)\n",
    "    prec = precision_score(y_dev, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_dev, y_pred)\n",
    "    \n",
    "    # Matriz de confusi√≥n\n",
    "    cm = confusion_matrix(y_dev, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    \n",
    "    resultados_comparacion.append({\n",
    "        'Estrategia': nombre,\n",
    "        'AUC': auc,\n",
    "        'F1': f1,\n",
    "        'Recall': rec,\n",
    "        'Precision': prec,\n",
    "        'Accuracy': acc,\n",
    "        'TP': tp,\n",
    "        'FN': fn,\n",
    "        'FP': fp,\n",
    "        'TN': tn\n",
    "    })\n",
    "\n",
    "df_comp = pd.DataFrame(resultados_comparacion).sort_values('Recall', ascending=False)\n",
    "\n",
    "print(f\"\\nüìä Tabla comparativa (ordenada por Recall):\")\n",
    "print(df_comp[['Estrategia', 'Recall', 'Precision', 'F1', 'AUC', 'Accuracy']].to_string(index=False))\n",
    "\n",
    "print(f\"\\nüìä Detalle de matriz de confusi√≥n:\")\n",
    "print(df_comp[['Estrategia', 'TP', 'FN', 'FP', 'TN']].to_string(index=False))\n",
    "\n",
    "# Identificar mejor estrategia (priorizar recall)\n",
    "mejor_estrategia_recall = df_comp.iloc[0]['Estrategia']\n",
    "mejor_estrategia_f1 = df_comp.sort_values('F1', ascending=False).iloc[0]['Estrategia']\n",
    "\n",
    "print(f\"\\nüèÜ Mejor estrategia por RECALL: {mejor_estrategia_recall}\")\n",
    "print(f\"   Recall: {df_comp.iloc[0]['Recall']:.4f}\")\n",
    "print(f\"   F1: {df_comp.iloc[0]['F1']:.4f}\")\n",
    "\n",
    "print(f\"\\nü•à Mejor estrategia por F1: {mejor_estrategia_f1}\")\n",
    "mejor_f1_row = df_comp[df_comp['Estrategia'] == mejor_estrategia_f1].iloc[0]\n",
    "print(f\"   F1: {mejor_f1_row['F1']:.4f}\")\n",
    "print(f\"   Recall: {mejor_f1_row['Recall']:.4f}\")\n",
    "\n",
    "# ============================================================\n",
    "# 7. AN√ÅLISIS DE IMPORTANCIA DE FEATURES\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"7. FEATURE IMPORTANCE DEL MEJOR MODELO\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Usar el modelo con mejor F1 para feature importance\n",
    "modelo_final = modelos[mejor_estrategia_f1]\n",
    "\n",
    "importances = pd.DataFrame({\n",
    "    'Feature': features,\n",
    "    'Importance': modelo_final.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(f\"\\nüîù Top 15 Features m√°s importantes:\")\n",
    "print(importances.head(15).to_string(index=False))\n",
    "\n",
    "# ============================================================\n",
    "# 8. GUARDAR RESULTADOS\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"8. GUARDANDO RESULTADOS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Guardar Excel\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "archivo_excel = ruta_resultados / f\"comparacion_estrategias_{timestamp}.xlsx\"\n",
    "\n",
    "with pd.ExcelWriter(archivo_excel, engine='openpyxl') as writer:\n",
    "    df_comp.to_excel(writer, sheet_name='Comparacion', index=False)\n",
    "    importances.to_excel(writer, sheet_name='Feature_Importance', index=False)\n",
    "    \n",
    "    # Agregar detalles de thresholds\n",
    "    df_threshold = pd.DataFrame(resultados_threshold)\n",
    "    df_threshold.to_excel(writer, sheet_name='Threshold_Analysis', index=False)\n",
    "\n",
    "print(f\"\\n‚úì Resultados guardados: {archivo_excel}\")\n",
    "\n",
    "# Guardar mejor modelo (seg√∫n F1)\n",
    "archivo_modelo = ruta_resultados / f\"modelo_optimizado_{timestamp}.pkl\"\n",
    "\n",
    "with open(archivo_modelo, 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'modelo': modelo_final,\n",
    "        'label_encoders': label_encoders,\n",
    "        'features': features,\n",
    "        'mejor_estrategia': mejor_estrategia_f1,\n",
    "        'threshold_optimo': best_threshold,\n",
    "        'class_weights': class_weights,\n",
    "        'metricas': mejor_f1_row.to_dict()\n",
    "    }, f)\n",
    "\n",
    "print(f\"‚úì Modelo optimizado guardado: {archivo_modelo}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ OPTIMIZACI√ìN COMPLETADA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\"\"\n",
    "üìä RESUMEN EJECUTIVO:\n",
    "\n",
    "üéØ OBJETIVO: Maximizar RECALL (identificar ni√±os con anemia)\n",
    "\n",
    "üèÜ MEJOR ESTRATEGIA POR RECALL:\n",
    "   Nombre: {mejor_estrategia_recall}\n",
    "   Recall: {df_comp.iloc[0]['Recall']:.4f} ({df_comp.iloc[0]['Recall']*100:.2f}%)\n",
    "   Precision: {df_comp.iloc[0]['Precision']:.4f}\n",
    "   F1: {df_comp.iloc[0]['F1']:.4f}\n",
    "   AUC: {df_comp.iloc[0]['AUC']:.4f}\n",
    "\n",
    "ü•à MEJOR ESTRATEGIA BALANCEADA (F1):\n",
    "   Nombre: {mejor_estrategia_f1}\n",
    "   F1: {mejor_f1_row['F1']:.4f}\n",
    "   Recall: {mejor_f1_row['Recall']:.4f}\n",
    "   Precision: {mejor_f1_row['Precision']:.4f}\n",
    "\n",
    "üí° INTERPRETACI√ìN:\n",
    "   - Threshold Optimizado: Ajusta punto de corte para priorizar recall\n",
    "   - Datos Balanceados: Genera muestras sint√©ticas para equilibrar clases\n",
    "   - Class Weights: Penaliza m√°s errores en clase minoritaria\n",
    "   \n",
    "üìÅ ARCHIVOS GENERADOS:\n",
    "   - {archivo_excel.name}\n",
    "   - {archivo_modelo.name}\n",
    "\n",
    "üî¨ PR√ìXIMOS PASOS:\n",
    "   1. Revisar matrices de confusi√≥n por estrategia\n",
    "   2. Validar interpretabilidad de features importantes\n",
    "   3. Evaluar en datos 2023-2024 (validaci√≥n temporal)\n",
    "   4. Considerar ensemble de mejores modelos\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024f7ec5-41eb-4221-b786-2f19baa1fabf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
